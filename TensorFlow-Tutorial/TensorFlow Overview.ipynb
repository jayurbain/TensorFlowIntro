{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TensorFlow Oveview\n",
    "\n",
    "Jay Urbain, PhD\n",
    "\n",
    "8/20/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics: basics of TensorFlow, from installation to creating, running, saving, and visualizing simple computational graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a powerful open source software library for numerical computation, particularly well suited and fine-tuned for large-scale Machine Learning. \n",
    "\n",
    "Released in 2015 as Open Source under the Apache licensing model.\n",
    "\n",
    "Great for deep learning applications:\n",
    "\n",
    "- Image recognition\n",
    "\n",
    "- Speech recognition\n",
    "\n",
    "- Image style transfer\n",
    "\n",
    "- Language translation\n",
    "\n",
    "Similar to theano, torch and pytorch deep learning models.\n",
    "\n",
    "TensorFlow is relatively complex. Frameworks like Keras sit on top of TensorFlow or Theano, and can simplify common tasks. Recommend learning TensorFlow basics before using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-style:normal;\">Focus on Supervised Learning</span>\n",
    "\n",
    "Training:\n",
    "\n",
    "<img src=\"supervised_learning.png\" alt=\"Supervised Learning\" style=\"width: 400px;\"/>\n",
    "\n",
    "Prediction:\n",
    "\n",
    "<img src=\"supervised_learning_prediction.png\" alt=\"Supervised Learning\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application development steps\n",
    "\n",
    "1) Build a model as a graph\n",
    "\n",
    "<img src=\"layer_graph.png\" alt=\"Build Model Phase\" style=\"width: 200px;\"/>\n",
    "\n",
    "2) Training Phase\n",
    "\n",
    "<img src=\"training_phase.png\" alt=\"Training Phase\" style=\"width: 350px;\"/>\n",
    "\n",
    "Monitor loss during training (print out or use TensorBoard):\n",
    "\n",
    "<img src=\"tensor_board.png\" alt=\"Monitor Loss during Training\" style=\"width: 350px;\"/>\n",
    "\n",
    "Save checkpoints of model in files, when loss low enough, use most recent model file.\n",
    "\n",
    "3) Testing Phase\n",
    "\n",
    "Evaluate mode on hold out data.\n",
    "\n",
    "4) Prediction Phase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors\n",
    "\n",
    "TensorFlow is designed to work with large datasets made up of many different attributes. \n",
    "\n",
    "Any data that you want to process with TensorFlow has to be stored in a multi-dimensional array. Multi-dimensional arrays are also called tensors.\n",
    "\n",
    "You contruct a computational graph that determines how data flows from one operation to the next.\n",
    "\n",
    "Its called TensorFlow because you're defining how data (or tensors) flow through a computational graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model follows a  basic principle:  first define in Python a graph of computations to perform , and then TensorFlow takes that graph and runs it efficiently using optimized C++ code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"font-weight:bold; font-style:normal;\">Computational Graph</span>\n",
    "<img src=\"mlst_0901.png\" alt=\"Computational Graph\" style=\"width: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to break up the graph into several chunks and run them in parallel across multiple CPUs or GPUs. \n",
    "\n",
    "TensorFlow also supports distributed computing, so you can train very large neural networks on gigantic training sets in a reasonable amount of time by splitting the computations across hundreds of servers.\n",
    "\n",
    "TensorFlow can train a network with millions of parameters on a training set composed of billions of instances with millions of features each. \n",
    "\n",
    "TensorFlow was developed by the Google Brain team and it powers many of Google’s large-scale services, such as Google Cloud Speech, Google Photos, and Google Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-style:normal;\">Distributed Computation</span>\n",
    "<img src=\"mlst_0902.png\" alt=\"Distributed Computation\" style=\"width: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow’s highlights:\n",
    "\n",
    "- TensorFlow was designed to be flexible, scalable, and production-ready. Existing frameworks arguably hit only two out of the three of these. \n",
    "\n",
    "- Runs on Windows, Linux, and macOS, <i>and</i> also on mobile devices, including both iOS and Android.\n",
    "\n",
    "- Provides a simplified Python API called TF.Learn2 (tensorflow.contrib.learn), compatible with Scikit-Learn. Can be used it to train various types of neural networks in just a few lines of code. \n",
    "\n",
    "- Provides another simple API called TF-slim (tensorflow.contrib.slim) to simplify building, training, and evaluating neural networks.\n",
    "\n",
    "- Several other high-level APIs have been built independently on top of TensorFlow, such as Keras or Pretty Tensor.\n",
    "\n",
    "- Main Python API offers much more flexibility (at the cost of higher complexity) to create all sorts of computations, including any neural network architecture you can think of.\n",
    "\n",
    "- It includes highly efficient C++ implementations of many ML operations, particularly those needed to build neural networks. There is also a C++ API to define your own high-performance operations.\n",
    "\n",
    "- Provides several advanced optimization nodes to search for the parameters that minimize a cost function. These are very easy to use since TensorFlow automatically takes care of computing the gradients of the functions you define. This is called automatic differentiating (or autodiff).\n",
    "\n",
    "- Comes with a great visualization tool called TensorBoard that allows you to browse through the computation graph, view learning curves, and more.\n",
    "\n",
    "- Google also launched a cloud service to run TensorFlow graphs.\n",
    "\n",
    "- One of the most popular open source projects on GitHub.\n",
    "\n",
    "#### Other Deep Learning libraries\n",
    "\n",
    "Caffe, Deeplearning4j, H2O.ai, MXNet, TensorFlow, Theano, Keras, Torch, PyTorch, Lua.\n",
    "\n",
    "Resources page on https://www.tensorflow.org/, or https://github.com/jtoy/awesome-tensorflow). \n",
    "\n",
    "Technical questions:  http://stackoverflow.com/ and tag your question with \"tensorflow\". \n",
    "\n",
    "File bugs and feature requests through GitHub. For general discussions, join the Google group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Open-ended Design\n",
    "\n",
    "- Can be used to model almost any series of calculations\n",
    "\n",
    "- Typically used to build deep neural networks\n",
    "\n",
    "- Due to its flexibility and sophisticated capabilities, has a somewhat high learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow requirements\n",
    "\n",
    "Development phase:\n",
    "- Linux, Mac OS X, Windows \n",
    "- Google's Cloud Machine Learning Engine service, FloydHub\n",
    "\n",
    "Runtime (inference phase): \n",
    "- Linux, Mac OS X, Windows  \n",
    "- Linux servers \n",
    "- Google's Cloud Machine Learning Engine service, FloydHub, etc. \n",
    "- iOS, Android "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Platform support\n",
    "\n",
    "- GPU Acceleration for nVidia GPUs:\n",
    "-- Supported in cloud computing envrionments\n",
    "\n",
    "- Written in C++\n",
    "\n",
    "- Python API is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing TensorFlow\n",
    "\n",
    "TensorFlow provides APIs for Python, C++, Haskell, Java, Go, Rust, and there’s also a third-party package for R called tensorflow. Python, is by far the most popular.\n",
    "\n",
    "\n",
    "Tensorflow install guide provides several options and can be a little confusing. \n",
    "https://www.tensorflow.org/install/\n",
    "\n",
    "My approach:  \n",
    "\n",
    "0) Create a project directory, open a terminal window in that directory.  \n",
    "\n",
    "1) Install Anaconda  \n",
    "https://www.continuum.io/downloads\n",
    "\n",
    "2) With anaconda installed, create a virtual environment for your tensor flow project:  \n",
    "conda create -n py3.5tf1.0 python=3.5\n",
    "\n",
    "List conda environments:   \n",
    "conda env list  \n",
    "\n",
    "Source your new environment:  \n",
    "source activate py3.5tf1.0  \n",
    "\n",
    "3) Install tensorflow in your sourced environment:  \n",
    "Add additional packages sources:  \n",
    "conda config --add channels conda-forge \n",
    "\n",
    "I typically want to select the version of tensorflow since the API changes rapidly. You review the available packages here (select the version at the top):  \n",
    "https://anaconda.org/conda-forge/tensorflow/files?version=0.12.1\n",
    "\n",
    "osx-64/tensorflow-1.0.0-py35_0.tar.bz2  \n",
    "win-64/tensorflow-1.0.0-py35_0.tar.bz2\n",
    "\n",
    "conda install -c conda-forge tensorflow=1.0.0 \n",
    "\n",
    "Note: This will install the latest compatible version of tensorflow:  \n",
    "conda install -c conda-forge tensorflow \n",
    "\n",
    "3) Install supporting packages. Note: TensorFlow will go ahead and install what it needs including numpy. The remaining packages come in handy: \n",
    "conda install numpy, pandas, matplotlib, scipy, scikit-learn, scikit-image\n",
    "\n",
    "These packages are helpful for running different environment kernels withing jupyter notebook:  \n",
    "\n",
    "conda install nb_conda, anaconda\n",
    "\n",
    "The following packages are necessary to use the Google Cloud Services API for accessing your machine learning models prgrammatically:  \n",
    "conda install google-api-python-client  \n",
    "pip install uritemplate.py  \n",
    "\n",
    "4) Start jupyter notebook from a terminal window accessible to your project \n",
    "jupyter notebook\n",
    "-- or --\n",
    "jupyter-notebook\n",
    "\n",
    "#### import tensorflow as tf\n",
    "This alias is a a convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested with Python 3.5, TensorFlow 1.0\n",
    "\n",
    "Note: In attempt to make notebook work well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "ID = \"tensorflow\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and running a graph\n",
    "\n",
    "<span style=\"font-weight:bold; font-style:normal;\">Computational Graph</span>\n",
    "<img src=\"mlst_0901.png\" alt=\"Computational Graph\" style=\"width: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code does not actually perform any computation. It just creates a computation graph. Even the variables are not initialized. \n",
    "\n",
    "To evaluate this graph, you need to open a TensorFlow session and use it to initialize the variables and evaluate $f$. \n",
    "\n",
    "A TensorFlow session takes care of placing the operations onto devices such as CPUs and GPUs, running them, and holding all the variable values. The following code creates a session, initializes the variables, evaluates $f$ and then closes the session (which frees up resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to repeat sess.run() is a bit cumbersome. This can be expressed more compactly with the Python *with* statement. \n",
    "\n",
    "Inside the *with* block, the session is set as the default session. Calling x.initializer.run() is equivalent to calling tf.get_default_session().run(x.initializer), and similarly f.eval() is equivalent to calling tf.get_default_session().run(f). The session is automatically closed at the end of the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of manually running the initializer for every single variable, you can use the global_variables_initializer() function. \n",
    "\n",
    "Note: that it does not actually perform the initialization immediately, but rather creates a node in the graph that will initialize all variables when it is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside Jupyter or within a Python shell you can create an *InteractiveSession*. The only difference from a regular Session is that when an InteractiveSession is created it automatically sets itself as the default session, so you don’t need a with block. But you do need to close the session manually when you are done with it.\n",
    "\n",
    "All these options can make things confusing. Pick a pattern of usage and stick with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A TensorFlow program is typically split into two parts: \n",
    "\n",
    "- the first part builds a computation graph (construction phase), and \n",
    "\n",
    "- the second part runs it (execution phase). \n",
    "\n",
    "The construction phase typically builds a computation graph representing the Machine Learning (ML) model and the computations required to train it. \n",
    "\n",
    "The execution phase generally runs a loop that evaluates a training step repeatedly (e.g., one step per mini-batch), gradually improving the model parameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any node you create is automatically added to the default graph. To insure you're starting with a fresh graph, call *reset_graph()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can manage multiple independent graphs by creating a new Graph and temporarily making it the default graph inside a with block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In Jupyter (or in a Python shell), it is common to run the same commands more than once while you are experimenting. As a result, you may end up with a default graph containing many duplicate nodes. One solution is to restart the Jupyter kernel (or the Python shell), but a more convenient solution is to just reset the default graph by running tf.reset_default_graph()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lifecycle of a Node Value\n",
    "\n",
    "When you evaluate a node, TensorFlow automatically determines the set of nodes that it depends on and it evaluates these nodes first. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  # 10\n",
    "    print(z.eval())  # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above defines a simple graph. \n",
    "\n",
    "Then it starts a session and runs the graph to evaluate y. TensorFlow automatically detects that y depends on w, which depends on x, so it first evaluates w, then x, then y, and returns the value of y. \n",
    "\n",
    "It is important to note that it will not reuse the result of the previous evaluation of w and x. In short, the preceding code evaluates w and x twice.\n",
    "\n",
    "All node values are dropped between graph runs, except variable values, which are maintained by the session across graph runs. A variable starts its life when its initializer is run, and it ends when the session is closed.\n",
    "\n",
    "If you want to evaluate y and z efficiently, without evaluating w and x twice as in the previous code, you must ask TensorFlow to evaluate both y and z in just one graph run, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)  # 10\n",
    "    print(z_val)  # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example using placeholders's which define a variable to be defined later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.   4.  20.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Turn off TensorFlow warning messages in program output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Define computational graph\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "\n",
    "addition = tf.add(X, Y, name=\"addition\")\n",
    "\n",
    "# Create the session\n",
    "with tf.Session() as session:\n",
    "\n",
    "    result = session.run(addition, feed_dict={X: [1, 2, 10], Y: [4, 2, 10]})\n",
    "\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.5tf1.0]",
   "language": "python",
   "name": "conda-env-py3.5tf1.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nav_menu": {
   "height": "603px",
   "width": "616px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
