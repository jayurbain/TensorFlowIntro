{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Using a Trained TensorFlow Model\n",
    "\n",
    "Jay Urbain, PhD\n",
    "\n",
    "8/20/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics: \n",
    "- Export model and run on Google's Cloud server\n",
    "- Practically infinite scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard Graph\n",
    "\n",
    "The TensorFlow model created and saved with chkpt files has many functions that can be called: \n",
    "- initialize values with init \n",
    "- pass input \n",
    "- generate output \n",
    "- train \n",
    "\n",
    "<img src=\"tensorboard_graph.png\" alt=\"TensorBoard Graph\" style=\"width: 400px;\"/>\n",
    "\n",
    "To deploy your model to a cloud computing environment, you need to configure your model for deployment by telling Google what we want to run.\n",
    "\n",
    "The model needs to be exported where we define what the start point of the model is that we want to run.\n",
    "\n",
    "- Can not use the standard tf.train.saver() function to save the model. Instead use tf.save_model.builder.SavedModelBuilder. Pass in the name of the folder.\n",
    "\n",
    "- Define inputs and outputs of the model we want Google to use. Can use Python dictionary 'inputs.' In this dictionary, list each tensor that needs to be filled in when the model is run.\n",
    "\n",
    "- Define the output the same was as the input 'output.' \n",
    "\n",
    "- Define what TensorFlow calls a signature def. Bascialy a method declaration in the programming language. Tells TF that to run the model, it should call a certain function with certain parameters. Use tf.saved_model.signature_def_utils.build_signature_def and pass in the inputs and outputs dictionaries.\n",
    "\n",
    "- Configure the model builder to tell it exactly how we want this model to be exported. Call model_builder.add_meta_graph_and_variables(). Meta graph is the structure of the computational graph, and the variables are the values we set on each node in the graph. Basically tells Google we want to export everything.\n",
    "\n",
    "- Create a signature def that lists all the signture defs the model supports using tf.saved_model.signature_constants.\n",
    "\n",
    "The exported model is saved in saved_model.pb. This model can be uploaed to the Google cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Training Cost: 0.17528082430362701  Testing Cost: 0.188410222530365\n",
      "Epoch: 5 - Training Cost: 0.02323892153799534  Testing Cost: 0.02728036418557167\n",
      "Epoch: 10 - Training Cost: 0.030099524185061455  Testing Cost: 0.03167065232992172\n",
      "Epoch: 15 - Training Cost: 0.01574300229549408  Testing Cost: 0.016836410388350487\n",
      "Epoch: 20 - Training Cost: 0.00992801133543253  Testing Cost: 0.010998598299920559\n",
      "Epoch: 25 - Training Cost: 0.010256705805659294  Testing Cost: 0.011087817139923573\n",
      "Epoch: 30 - Training Cost: 0.005949163343757391  Testing Cost: 0.006453320849686861\n",
      "Epoch: 35 - Training Cost: 0.005320586264133453  Testing Cost: 0.005596966948360205\n",
      "Epoch: 40 - Training Cost: 0.004163410514593124  Testing Cost: 0.004361606668680906\n",
      "Epoch: 45 - Training Cost: 0.0034807457122951746  Testing Cost: 0.0036233121063560247\n",
      "Epoch: 50 - Training Cost: 0.002664419123902917  Testing Cost: 0.0028396183624863625\n",
      "Epoch: 55 - Training Cost: 0.002142256125807762  Testing Cost: 0.002254687948152423\n",
      "Epoch: 60 - Training Cost: 0.0017003563698381186  Testing Cost: 0.0018673741724342108\n",
      "Epoch: 65 - Training Cost: 0.0013639421667903662  Testing Cost: 0.0014910754980519414\n",
      "Epoch: 70 - Training Cost: 0.0011464848648756742  Testing Cost: 0.001247313222847879\n",
      "Epoch: 75 - Training Cost: 0.0009532765834592283  Testing Cost: 0.001082856091670692\n",
      "Epoch: 80 - Training Cost: 0.0007922614458948374  Testing Cost: 0.0008995889802463353\n",
      "Epoch: 85 - Training Cost: 0.0006779448594897985  Testing Cost: 0.000792677397839725\n",
      "Epoch: 90 - Training Cost: 0.0005776742473244667  Testing Cost: 0.0006825428572483361\n",
      "Epoch: 95 - Training Cost: 0.0004979561199434102  Testing Cost: 0.0006172314751893282\n",
      "Final Training cost: 0.00044790678657591343\n",
      "Final Testing cost: 0.0005611187079921365\n",
      "The actual earnings of Game #1 were $247537.0\n",
      "Our neural network predicted earnings of $234270.390625\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'exported_model/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Turn off TensorFlow warning messages in program output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Load training data set from CSV file\n",
    "training_data_df = pd.read_csv(\"create_model/sales_data_training.csv\", dtype=float)\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_training = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y_training = training_data_df[['total_earnings']].values\n",
    "\n",
    "# Load testing data set from CSV file\n",
    "test_data_df = pd.read_csv(\"create_model/sales_data_test.csv\", dtype=float)\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_testing = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_testing = test_data_df[['total_earnings']].values\n",
    "\n",
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.\n",
    "X_scaled_testing = X_scaler.transform(X_testing)\n",
    "Y_scaled_testing = Y_scaler.transform(Y_testing)\n",
    "\n",
    "# Define model parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "display_step = 5\n",
    "\n",
    "# Define how many inputs and outputs are in our neural network\n",
    "number_of_inputs = 9\n",
    "number_of_outputs = 1\n",
    "\n",
    "# Define how many neurons we want in each layer of our neural network\n",
    "layer_1_nodes = 50\n",
    "layer_2_nodes = 100\n",
    "layer_3_nodes = 50\n",
    "\n",
    "# Section One: Define the layers of the neural network itself\n",
    "\n",
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "# Layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_3_output, weights) + biases\n",
    "\n",
    "# Section Two: Define the cost function of the neural network that will be optimized during training\n",
    "\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n",
    "\n",
    "# Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize a session so that we can run TensorFlow operations\n",
    "with tf.Session() as session:\n",
    "\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create log file writers to record training progress.\n",
    "    # We'll store training and testing log data separately.\n",
    "    training_writer = tf.summary.FileWriter('./logs/training', session.graph)\n",
    "    testing_writer = tf.summary.FileWriter('./logs/testing', session.graph)\n",
    "\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "\n",
    "        # Every few training steps, log our progress\n",
    "        if epoch % display_step == 0:\n",
    "            # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "            training_cost, training_summary = session.run([cost, summary], feed_dict={X: X_scaled_training, Y:Y_scaled_training})\n",
    "            testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: X_scaled_testing, Y:Y_scaled_testing})\n",
    "\n",
    "            # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "            training_writer.add_summary(training_summary, epoch)\n",
    "            testing_writer.add_summary(testing_summary, epoch)\n",
    "\n",
    "            # Print the current training status to the screen\n",
    "            print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "\n",
    "    # Training is now complete!\n",
    "\n",
    "    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "    final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "    final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n",
    "\n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "\n",
    "    # Now that the neural network is trained, let's use it to make predictions for our test data.\n",
    "    # Pass in the X testing data and run the \"prediciton\" operation\n",
    "    Y_predicted_scaled = session.run(prediction, feed_dict={X: X_scaled_testing})\n",
    "\n",
    "    # Unscale the data back to it's original units (dollars)\n",
    "    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n",
    "\n",
    "    real_earnings = test_data_df['total_earnings'].values[0]\n",
    "    predicted_earnings = Y_predicted[0][0]\n",
    "\n",
    "    print(\"The actual earnings of Game #1 were ${}\".format(real_earnings))\n",
    "    print(\"Our neural network predicted earnings of ${}\".format(predicted_earnings))\n",
    "\n",
    "    model_builder = tf.saved_model.builder.SavedModelBuilder(\"exported_model\")\n",
    "\n",
    "    inputs = {\n",
    "        'input': tf.saved_model.utils.build_tensor_info(X)\n",
    "        }\n",
    "    outputs = {\n",
    "        'earnings': tf.saved_model.utils.build_tensor_info(prediction)\n",
    "        }\n",
    "\n",
    "    signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "    )\n",
    "\n",
    "    model_builder.add_meta_graph_and_variables(\n",
    "        session,\n",
    "        tags=[tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={\n",
    "            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_def\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model_builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a new Google account\n",
    "\n",
    "To host ML models on the Google Cloud service you need to: \n",
    "- setp up your Google account \n",
    "- install the Google Cloud SDK\n",
    "\n",
    "\n",
    "Log into console.cloud.google.com\n",
    "\n",
    "google_cloud_platform.png\n",
    "\n",
    "Create a new project from the project drop down called TensorFlowVGSales.\n",
    "\n",
    "google_cloud_tfvgsales_project.png\n",
    "\n",
    "Your project will crete a unique key. Use this to access it from your program.\n",
    "\n",
    "google_cloud_tfvgsales_project_home.png\n",
    "\n",
    "Enable the Google Cloud Machine Learning API by selecting 'APIs and Services' and selecting 'Library.' Enable the Machine Learning API.\n",
    "\n",
    "google_cloud_api.png\n",
    "\n",
    "You'll need to provide billing details.\n",
    "\n",
    "billing_account.png\n",
    "\n",
    "Download and install the Google Cloud SDK to enable interaction with Google Cloud Services. Go to:\n",
    "http://cloud.google.com/sdk/downloads\n",
    "\n",
    "google_cloud_sdk\n",
    "\n",
    "Run the following commaind: \n",
    "$gcloud init\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ gcloud init\n",
    "Welcome! This command will take you through the configuration of gcloud.\n",
    "\n",
    "Your current configuration has been set to: [default]\n",
    "\n",
    "You can skip diagnostics next time by using the following flag:\n",
    "  gcloud init --skip-diagnostics\n",
    "\n",
    "Network diagnostic detects and fixes local network connection issues.\n",
    "Checking network connection...done.                                            \n",
    "Reachability Check passed.\n",
    "Network diagnostic (1/1 checks) passed.\n",
    "\n",
    "You must log in to continue. Would you like to log in (Y/n)?  Y\n",
    "\n",
    "Your browser has been opened to visit:\n",
    "\n",
    "    https://accounts.google.com/o/oauth2/auth?redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&prompt=select_account&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&access_type=offline\n",
    "\n",
    "\n",
    "You are logged in as: [jay.urbain@gmail.com].\n",
    "\n",
    "Pick cloud project to use: \n",
    " [1] api-project-1075001585541\n",
    " [2] api-project-221567196565\n",
    " [3] api-project-2264943174\n",
    " [4] api-project-519492129980\n",
    " [5] api-project-614100502785\n",
    " [6] api-project-675683730300\n",
    " [7] api-project-815932717796\n",
    " [8] buoyant-country-125622\n",
    " [9] core-arena-739\n",
    " [10] crested-dialect-174317\n",
    " [11] guestbookjayurbain\n",
    " [12] gwajayurbain\n",
    " [13] model-calling-110122\n",
    " [14] named-vine-110321\n",
    " [15] nodechat-174317\n",
    " [16] rare-deployment-110319\n",
    " [17] single-purpose-742\n",
    " [18] stoked-cosine-110320\n",
    " [19] tensorflowvgsales\n",
    " [20] wise-brook-744\n",
    " [21] Create a new project\n",
    "Please enter numeric choice or text value (must exactly match list \n",
    "item):  19\n",
    "\n",
    "Your current project has been set to: [tensorflowvgsales].\n",
    "\n",
    "API [compute.googleapis.com] not enabled on project [849825182946]. \n",
    "Would you like to enable and retry?  (Y/n)?  Y\n",
    "\n",
    "Do you want to configure Google Compute Engine \n",
    "(https://cloud.google.com/compute) settings (Y/n)?  Y\n",
    "\n",
    "Which Google Compute Engine zone would you like to use as project \n",
    "default?\n",
    "If you do not specify a zone via a command line flag while working \n",
    "with Compute Engine resources, the default is assumed.\n",
    " [1] asia-east1-c\n",
    " [2] asia-east1-a\n",
    " [3] asia-east1-b\n",
    " [4] asia-northeast1-a\n",
    " [5] asia-northeast1-c\n",
    " [6] asia-northeast1-b\n",
    " [7] asia-southeast1-b\n",
    " [8] asia-southeast1-a\n",
    " [9] australia-southeast1-b\n",
    " [10] australia-southeast1-a\n",
    " [11] australia-southeast1-c\n",
    " [12] europe-west1-c\n",
    " [13] europe-west1-b\n",
    " [14] europe-west1-d\n",
    " [15] europe-west2-a\n",
    " [16] europe-west2-b\n",
    " [17] europe-west2-c\n",
    " [18] europe-west3-c\n",
    " [19] europe-west3-a\n",
    " [20] europe-west3-b\n",
    " [21] us-central1-b\n",
    " [22] us-central1-f\n",
    " [23] us-central1-a\n",
    " [24] us-central1-c\n",
    " [25] us-east1-b\n",
    " [26] us-east1-d\n",
    " [27] us-east1-c\n",
    " [28] us-east4-b\n",
    " [29] us-east4-a\n",
    " [30] us-east4-c\n",
    " [31] us-west1-a\n",
    " [32] us-west1-b\n",
    " [33] us-west1-c\n",
    " [34] Do not set default zone\n",
    "Please enter numeric choice or text value (must exactly match list \n",
    "item):  \n",
    "Please enter a value between 1 and 34, or a value present in the list:  34\n",
    "\n",
    "Which Google Compute Engine region would you like to use as project \n",
    "default?\n",
    "If you do not specify a region via a command line flag while working \n",
    "with Compute Engine resources, the default is assumed.\n",
    " [1] us-central1\n",
    " [2] europe-west1\n",
    " [3] us-west1\n",
    " [4] asia-east1\n",
    " [5] us-east1\n",
    " [6] asia-northeast1\n",
    " [7] asia-southeast1\n",
    " [8] us-east4\n",
    " [9] australia-southeast1\n",
    " [10] europe-west2\n",
    " [11] europe-west3\n",
    " [12] Do not set default region\n",
    "Please enter numeric choice or text value (must exactly match list \n",
    "item):  1\n",
    "\n",
    "Your project default Compute Engine region has been set to [us-central1].\n",
    "You can change it by running [gcloud config set compute/region NAME].\n",
    "\n",
    "Created a default .boto configuration file at [/Users/jayurbain/.boto]. See this file and\n",
    "[https://cloud.google.com/storage/docs/gsutil/commands/config] for more\n",
    "information about configuring Google Cloud Storage.\n",
    "Your Google Cloud SDK is configured and ready to use!\n",
    "\n",
    "* Commands that require authentication will use jay.urbain@gmail.com by default\n",
    "* Commands will reference project `tensorflowvgsales` by default\n",
    "* Compute Engine commands will use region `us-central1` by default\n",
    "Run `gcloud help config` to learn how to change individual settings\n",
    "\n",
    "This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.\n",
    "Run `gcloud topic configurations` to learn more.\n",
    "\n",
    "Some things to try next:\n",
    "\n",
    "* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.\n",
    "* Run `gcloud topic -h` to learn about advanced features of the SDK like arg files and output formatting\n",
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two step process to run your model in the cloud:  \n",
    "- upload model files to a Google Cloud storage bucket \n",
    "- create a new Gogle Cloud machine learning model using the files we have uploaded\n",
    "\n",
    "Once the model is in the Cloud, we can use it by sending it data. Use the *sample_input_prescaled.json* included in the project. This is a JSON file with the name of the model's iput, and then the values you want to feed into the model. The contents include the name of the model's input, and the values you want to feed into the model (the 9 feature values).\n",
    "\n",
    "{ \"input\": [0.4999, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5] }\n",
    "\n",
    "Open a terminal window in the directory where your model is exported.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ pwd\n",
    "/Users/jayurbain/Dropbox/TensorFlowIntro/TensorFlow-Tutorial\n",
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ ls exported_model\n",
    "saved_model.pb\tvariables\n",
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can upload the model files to a Gogle Cloud storage bucket. \n",
    "- create a google storage bucket  \n",
    "- upload model files recursively to the bucket"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ gsutil mb -l us-central1 gs://tensorflowvgsales\n",
    "Creating gs://tensorflowvgsales/...\n",
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ gsutil cp -R exported_model/*  gs://tensorflowvgsales\n",
    "Copying file://exported_model/saved_model.pb [Content-Type=application/octet-stream]...\n",
    "Copying file://exported_model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
    "Copying file://exported_model/variables/variables.index [Content-Type=application/octet-stream]...\n",
    "- [3 files][198.5 KiB/198.5 KiB]                                                \n",
    "Operation completed over 3 objects/198.5 KiB.                                    \n",
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model files are now on Google cloud service.\n",
    "\n",
    "Now create a model placeholder, \n",
    "\n",
    "gcloud ml-engine models create vgsales --regions us-central1\n",
    "\n",
    "gcloud ml-engine versions create v1 --model=vgsales --origin gs://tensorflowvgsales\n",
    "    \n",
    "gcloud ml-engine predict create v1 --model=vgsales --json-instances=sample_input_prescaled.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ gcloud ml-engine models create vgsales --regions us-central1\n",
    "Created ml engine model [projects/tensorflowvgsales/models/vgsales].\n",
    "jays-mbp-2:TensorFlow-Tutorial jayurbain$ gcloud ml-engine versions create v1 --model=vgsales --origin gs://tensorflowvgsales\n",
    "Creating version (this might take a few minutes)......-                                            \n",
    "\n",
    "\n",
    "Creating version (this might take a few minutes)......done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Time to make a prediction:\n",
    "    \n",
    "gcloud ml-engine predict --model=vgsales --json-instances=sample_input_prescaled.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(py3.5tf1.0) jays-mbp-2:TensorFlow-Tutorial jayurbain$ gcloud ml-engine predict --model=vgsales --json-instances=sample_input_prescaled.json\n",
    "EARNINGS\n",
    "[0.18396909534931183]\n",
    "(py3.5tf1.0) jays-mbp-2:TensorFlow-Tutorial jayurbain$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use your model in the cloud from anywere.\n",
    "\n",
    "There are several ways to use the model.\n",
    "- use json as we did above  \n",
    "- upload file \n",
    "- programming api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling machine learning model from Python\n",
    "\n",
    "developers.google.com/api-client-library\n",
    "\n",
    "- Create a credentials file  \n",
    "- Write code using API\n",
    "\n",
    "Open: console.cloud.google.com  \n",
    "Make sure you have the correct project selected \n",
    "Select APIs and Credentials -> Credentials -> Create credentials\n",
    "\n",
    "\n",
    "create_services_account_key.png\n",
    "\n",
    "Save the credential files into your project directory.\n",
    "\n",
    "Create an app to call the machine learning service api:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'uritemplate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-520ab7ed13e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscovery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Change this values to match your project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPROJECT_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TensorFlowVGSales\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py3.5tf1.0/lib/python3.5/site-packages/googleapiclient/discovery.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Third-party imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttplib2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0muritemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Local imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'uritemplate'"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Change this values to match your project\n",
    "PROJECT_ID = \"TensorFlowVGSales\"\n",
    "MODEL_NAME = \"vgsales\"\n",
    "CREDENTIALS_FILE = \"TensorFlowVGSales-ecc880ec0bea.json\"\n",
    "\n",
    "# These are the values we want a prediction for\n",
    "inputs_for_prediction = [\n",
    "    {\"input\": [0.4999, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5]}\n",
    "]\n",
    "\n",
    "# Connect to the Google Cloud-ML Service\n",
    "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
    "service = googleapiclient.discovery.build('ml', 'v1', credentials=credentials)\n",
    "\n",
    "# Connect to our Prediction Model\n",
    "name = 'projects/{}/models/{}'.format(PROJECT_ID, MODEL_NAME)\n",
    "response = service.projects().predict(\n",
    "    name=name,\n",
    "    body={'instances': inputs_for_prediction}\n",
    ").execute()\n",
    "\n",
    "# Report any errors\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "# Grab the results from the response object\n",
    "results = response['predictions']\n",
    "\n",
    "# Print the results!\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.5tf1.0]",
   "language": "python",
   "name": "conda-env-py3.5tf1.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
